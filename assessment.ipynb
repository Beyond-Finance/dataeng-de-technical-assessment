{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineer - Technical Assessment\n",
    "\n",
    "In this section of the interview at Beyond Finance, you will be assessed on your ability to perform several Data Engineering tasks. To perform well on this task, you will demonstate competence in the following areas:\n",
    "\n",
    "* preprocessing data to prepare for a database load\n",
    "* understanding entity relationships in a database\n",
    "* merging data from different tables\n",
    "* filtering data to relevant subsets\n",
    "* calculating aggregations and descriptive statistics\n",
    "\n",
    "It will be pretty difficult to complete all questions in the allotted time. Your goal is not to speed through the answers, but to come up with answers that demonstrate your knowledge. It's more about your thought process and logic than getting the right answer or your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started\n",
    "\n",
    "This exercise will be broken into 2 parts\n",
    "1. Data Processing\n",
    "2. Data Wrangling\n",
    "\n",
    "### Data Processing\n",
    "In this section you will take files from the ./raw_data/ subfolders, combine them into a single newline-delimited `json.gz` file per subfolder, and place that CSV file in a ./processed_data/ directory. You may have to do some light investigation into the data files to understand their file formats and delimiters\n",
    "\n",
    "**Example**\n",
    "\n",
    "Files\n",
    "- ./raw_data/tracks/tracks_0.csv\n",
    "- ./raw_data/tracks/tracks_1.json\n",
    "- ./raw_data/tracks/tracks_2.csv\n",
    "- etc... \n",
    "\n",
    "should be combined into a single file ./processed_data/tracks.json.gz\n",
    "\n",
    "**What we look for**\n",
    "\n",
    "- Can you handle all subfolders in a single pass over the raw data files?\n",
    "- How can you limit memory consumption? (hint `chunksize`)\n",
    "\n",
    "### Data Wrangling\n",
    "For this section, we'll pretend you loaded the raw data plus additional tables into a small SQLite database containing roughly a dozen tables. **We've provided this database for you so don't worry about loading it yourself**. If you are not familiar with the SQLite database, it uses a fairly complete and standard SQL syntax, though does not many advanced analytics functions. Consider it just a remote datastore for storing and retrieving data from. \n",
    "\n",
    "![](db-diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing (40 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import os\n",
    "\n",
    "#!pip install memory_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n",
      "Done!\n",
      "peak memory: 87.26 MiB, increment: 0.00 MiB\n"
     ]
    }
   ],
   "source": [
    "%%memit\n",
    "# ... your code here\n",
    "\n",
    "## Create Processed Data directory \n",
    "if not os.path.exists('processed_data'):\n",
    "    os.makedirs('processed_data')\n",
    "\n",
    "## List of Folders\n",
    "raw_data_dir = './raw_data/'\n",
    "read_folders = os.listdir(raw_data_dir)\n",
    "\n",
    "\n",
    "\n",
    "## Read  folder data and write to processed data folder with final output\n",
    "def processed_data(folder):\n",
    "    print(\"function started\")\n",
    "    final_df = pd.DataFrame()\n",
    "    path = raw_data_dir + folder + '/'\n",
    "    files = os.listdir(path)\n",
    "    print(files)\n",
    "    for j in range(len(files)):\n",
    "        file = path + files[j]\n",
    "        if file.endswith(\".json\"):\n",
    "            df = pd.read_json(file,lines=True, chunksize=1000)\n",
    "        elif file.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file,iterator=True, chunksize=1000)\n",
    "        final_df = final_df.append(df)\n",
    "    final_df.to_json(f'processed_data/{folder}.json.gz', orient='records', lines=True,compression='gzip')\n",
    "\n",
    "## Multi Processing to run all sub folders at same time (number of processer is based on cpu count)\n",
    "import multiprocessing\n",
    "\n",
    "if __name__==\"__main__\":\n",
    "\n",
    "    folders = []\n",
    "    n = int(multiprocessing.cpu_count()/2)\n",
    "    for i in range(0, len(read_folders), n):\n",
    "        folder = read_folders[i:i + n]\n",
    "        pool_objects = []\n",
    "        for j in range(len(folder)):\n",
    "            p = multiprocessing.Process(target=processed_data, args=(folder[j], ))\n",
    "            p.start()\n",
    "            pool_objects.append(p)\n",
    "\n",
    "        for p in pool_objects:\n",
    "            p.join()\n",
    "\n",
    "    # All processes finished\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Wrangling (20 minutes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql \n",
    "%sql sqlite:///db/sqlite/chinook.db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "con = sqlite3.connect(\"db/sqlite/chinook.db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. How many different customers are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///db/sqlite/chinook.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>cnt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>59</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(59,)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select count(distinct customerid) as cnt from customers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. How long is the longest track in minutes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///db/sqlite/chinook.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>minutes</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>88</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[(88,)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select max(milliseconds)/60000 as minutes from tracks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Which genre has the shortest average track length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///db/sqlite/chinook.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>genre_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Rock And Roll</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Rock And Roll',)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select b.name as genre_name from \n",
    "(select t1.genreid,min(average)  from \n",
    "(select genreid,avg(milliseconds) as average from tracks group by genreid)t1 )a \n",
    "join genres b on a.genreid = b.genreid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Which artist shows up in the most playlists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///db/sqlite/chinook.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>artist_name</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Iron Maiden</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Iron Maiden',)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select artist_name from (select t1.artist_name,max(t1.cnt) from (Select a.name as artist_name,count(e.name) as cnt\n",
    "From artists a\n",
    "Join albums b \n",
    "On a.artistid = b.artistid\n",
    "join tracks c\n",
    "on b.albumid = c.albumid\n",
    "join playlist_track d \n",
    "on c.trackid = d.trackid\n",
    "join playlists e \n",
    "on d.playlistid = e.playlistid\n",
    "Group By a.Name)t1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. What was the most popular album among these customers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * sqlite:///db/sqlite/chinook.db\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "    <tr>\n",
       "        <th>title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "        <td>Minha Historia</td>\n",
       "    </tr>\n",
       "</table>"
      ],
      "text/plain": [
       "[('Minha Historia',)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "select title from (select a.title,count(c.quantity) as cnt from albums a \n",
    "join tracks b \n",
    "on a.albumid = b.albumid\n",
    "join invoice_items c \n",
    "on b.trackid = c.trackid group by a.title ) order by cnt desc limit 1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
